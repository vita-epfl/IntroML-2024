{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "korean-married",
   "metadata": {},
   "source": [
    "# Intro to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-petite",
   "metadata": {},
   "source": [
    "<hr style=\"clear:both\">\n",
    "\n",
    "This notebook is part of a series of exercises for the CIVIL-226 Introduction to Machine Learning for Engineers course at EPFL. Copyright (c) 2021 [VITA](https://www.epfl.ch/labs/vita/) lab at EPFL  \n",
    "Use of this source code is governed by an MIT-style license that can be found in the LICENSE file or at https://www.opensource.org/licenses/MIT\n",
    "\n",
    "**Author(s):** [David Mizrahi](mailto:david.mizrahi@epfl.ch)\n",
    "<hr style=\"clear:both\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-adelaide",
   "metadata": {},
   "source": [
    "[pandas](https://pandas.pydata.org/) is a fast, powerful and flexible package for data manipulation and analysis in Python, built on top of NumPy.\n",
    "\n",
    "It provides:\n",
    "- a fast and efficient DataFrame object for data manipulation, with integrated indexing\n",
    "- tools for reading and writing data between in-memory data and various file formats \n",
    "- easy handling of missing data\n",
    "- easy conversion to and from NumPy arrays \n",
    "- [and much more](https://pandas.pydata.org/about/index.html)\n",
    "\n",
    "Pandas has quickly become a fundamental package for data science in Python. In this tutorial, we'll cover the basics of this package and show how it can be used to handle real-world data for ML applications.\n",
    "\n",
    "In addition, we'll also briefly cover the seaborn package, which we'll use to generate informative plots from pandas data.\n",
    "\n",
    "\n",
    "<img src=\"images/stack_overflow_traffic.png\" width=500></img>\n",
    "\n",
    "Source: https://stackoverflow.blog/2017/09/14/python-growing-quickly/\n",
    "\n",
    "**Note:** Unlike previous tutorials, there is no code to write here. Just read through it and run the cells. For a more hands-on tutorial, we recommend the [pandas course on Kaggle](https://www.kaggle.com/learn/pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-cooperative",
   "metadata": {},
   "source": [
    "## 1. Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-slope",
   "metadata": {},
   "source": [
    "A **DataFrame** is the primary data structure in Pandas. It is a data table composed of rows and columns.\n",
    "\n",
    "You can also refer to the 2 dimensions of a DataFrame as axes, with axis 0 corresponding to the row index, and axis 1 to the column index.\n",
    "\n",
    "Each column of a DataFrame can be of a different type such as integers, floats, booleans, datetime or even `object`, which can hold any Python object \n",
    "\n",
    "<img src=\"images/dataframe.png\" width=400></img>\n",
    "\n",
    "In this part, we'll cover basic pandas operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-peninsula",
   "metadata": {},
   "source": [
    "### Creating a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[21, 184], [19, 168], [36, 178], [34, 175], [63, 159], [25, 165]])\n",
    "# df is an abbrevation of DataFrame\n",
    "df = pd.DataFrame(data=data, columns=[\"age\", \"height (cm)\"])\n",
    "\n",
    "# Show DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-mixer",
   "metadata": {},
   "source": [
    "### Accessing specific columns\n",
    "\n",
    "Accessing a single object returns a [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html), which is a one-dimensional ndarray with axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing only the age column (as a pd.Series object)\n",
    "df[\"age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-saturday",
   "metadata": {},
   "source": [
    "### Adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"] = [\"M\", \"F\", \"M\", \"F\", \"F\", \"M\"]\n",
    "df[\"height (m)\"] = df[\"height (cm)\"] / 100\n",
    "\n",
    "# Show updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-worship",
   "metadata": {},
   "source": [
    "### Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"height (m)\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-boundary",
   "metadata": {},
   "source": [
    "By default, operations in pandas are not in-place (i.e. they return a copy, and don't modify the original object). This can be changed by adding `inplace=False` as a parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-parliament",
   "metadata": {},
   "source": [
    "### Adding rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append({\"age\": 29, \"height (cm)\": 172, \"sex\": \"F\"}, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-salon",
   "metadata": {},
   "source": [
    "### Boolean indexing / slicing\n",
    "\n",
    "More info: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the df DataFrame, show me only the rows in which the \"sex\" column is \"F\"\n",
    "df[df[\"sex\"] == \"F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the df DataFrame, show me only the rows in which the \"sex\" column is \"M\" AND (&) the \"age\" is below 30\n",
    "df[(df[\"sex\"] == \"M\") & (df[\"age\"] < 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the df DataFrame, show me only the rows in which the \"sex\" column is \"F\" OR (|) in which (the \"sex\" column is \"M\" AND (&) the age is below 30)\n",
    "df[(df[\"sex\"] == \"F\") | ((df[\"sex\"] == \"M\") & (df[\"age\"] < 30))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-sodium",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by age in ascending order\n",
    "df.sort_values(by=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values first by sex, then by age in descending order\n",
    "df.sort_values(by=[\"sex\", \"age\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-whole",
   "metadata": {},
   "source": [
    "###  Grouping\n",
    "\n",
    "More info: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"sex\")[\"height (cm)\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-renewal",
   "metadata": {},
   "source": [
    "## 2. I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-steal",
   "metadata": {},
   "source": [
    "Pandas supports reading from and writing to many data formats, such as CSV, JSON, Pickle, Excel, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-cornell",
   "metadata": {},
   "source": [
    "### Writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-arrangement",
   "metadata": {},
   "source": [
    "Here's how to write our current DataFrame `df` to a file.\n",
    "\n",
    "Here are some of the formats you can write to:\n",
    "- `.to_csv`\n",
    "- `.to_json`\n",
    "- `.to_excel`\n",
    "- `.to_pickle`\n",
    "- `.to_clipboard`\n",
    "- `.to_markdown`\n",
    "- `.to_latex` (very useful for papers / reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=False means we don't want to add our index to the CSV file\n",
    "df.to_csv(\"demo_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-rates",
   "metadata": {},
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-chile",
   "metadata": {},
   "source": [
    "Now, we'll load a real-world dataset which contains data for 891 of the Titanic's passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-sweet",
   "metadata": {},
   "source": [
    "Here are some of the formats you can read from:\n",
    "- `pd.read_csv`\n",
    "- `pd.read_json`\n",
    "- `pd.read_excel`\n",
    "- `pd.read_pickle`\n",
    "- `pd.read_clipboard`\n",
    "\n",
    "More info about I/O in pandas: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-brief",
   "metadata": {},
   "source": [
    "## 3. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-society",
   "metadata": {},
   "source": [
    "Let's suppose we want to use our  dataset to create a model that predicts which passengers survived the Titanic shipwreck. \n",
    "\n",
    "<img src=\"images/titanic.jpg\" width=400></img>\n",
    "\n",
    "What do we know about the Titanic? It's a boat. It hit an iceberg. It sank. This is definitely not enough information to build a solid classifier.\n",
    "\n",
    "\n",
    "This is where exploratory data analysis comes into play. It helps us understand how our data looks like, and how it can be processed and manipulated into something meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-qualification",
   "metadata": {},
   "source": [
    "### Preview\n",
    "\n",
    "When dataframes are large, it's not feasible to view the entirety of rows. The `head()`, `tail()` and `sample()` functions can be used to glance at a few of the rows of the datasets and better understand how the data looks like.\n",
    "\n",
    "- `.head(n)` returns the first n rows\n",
    "- `.tail(n)` returns the last n rows\n",
    "- `.sample(n)` returns a random sample of the rows (can also be `.sample(frac=m)` to return a fraction of the total number of rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-latitude",
   "metadata": {},
   "source": [
    "### Shape and column information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-excerpt",
   "metadata": {},
   "source": [
    "`shape` works just like it does in NumPy. Here, the first value is the number of rows and the second is the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-tomorrow",
   "metadata": {},
   "source": [
    "`info()` prints a concise summary of the DataFrame. It gives, for each column, its type and the number of columns that are non-null (not `NaN`). It also provides the memory usage of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-roots",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-guest",
   "metadata": {},
   "source": [
    "`describe()` generates descriptive statistics, such as the mean, standard deviation, mean, max and quartiles.\n",
    "\n",
    "By default, it only analyzes the numeric columns of a DataFrame, but this can be changed by adding `include=\"all\"` as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-blackberry",
   "metadata": {},
   "source": [
    "### Unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-century",
   "metadata": {},
   "source": [
    "Some of these columns can be a bit obscure, using `.unique()` can shed some light about which values are contained in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"who\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"embarked\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"embark_town\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"alive\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"deck\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-playing",
   "metadata": {},
   "source": [
    "### Redundant information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-malta",
   "metadata": {},
   "source": [
    "Looking at this data, it seems like \"survived\" and \"alive\" are quite similar, but are written in a different way. Let's see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[(titanic[\"survived\"] == 1) & (titanic[\"alive\"] == \"yes\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[(titanic[\"survived\"] == 1) & (titanic[\"alive\"] == \"no\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-jaguar",
   "metadata": {},
   "source": [
    "Using `.all()`, we can check if these two columns actually encode the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "((titanic[\"alive\"] == \"yes\") == (titanic[\"survived\"] == 1)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "((titanic[\"alive\"] == \"no\") == (titanic[\"survived\"] == 0)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-traveler",
   "metadata": {},
   "source": [
    "This also applies for the columns \"embarked\" and \"embark_town\", as well as \"pclass\" and \"class\", so we'll only keep one of each. In addition, the \"adult_male\" column can be directly obtained from the \"who\" column, so we'll remove it and work on this reduced DataFrame for the rest of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\"survived\", \"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embark_town\", \"deck\", \"who\", \"alone\"]\n",
    "titanic = titanic[keep_cols].copy()\n",
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-atlas",
   "metadata": {},
   "source": [
    "Let's now clarify what these columns mean:\n",
    "- **survived**: Survival of the passenger (0 = No, 1 = Yes)\n",
    "- **pclass**: Ticket class (1= 1st, 2 = 2nd, 3 = 3rd)\n",
    "- **sex**: Sex\n",
    "- **age**: Age\n",
    "- **sibsp**: # of siblings / spouses aboard the Titanic\n",
    "- **parch**: # of parents / children aboard the Titanic\n",
    "- **fare**: Passenger fare\n",
    "- **embark_town**: Port of embarkation (Southampton, Cherbourg, Queenstown)\n",
    "- **deck**: Ship deck (A to F)\n",
    "- **who**: man, woman or child\n",
    "- **alone**: Whether the passenger is alone or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-rider",
   "metadata": {},
   "source": [
    "## 4. Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-ordinance",
   "metadata": {},
   "source": [
    "Let's now see how we can generate informative plots from DataFrames.\n",
    "\n",
    "Plots are a great way to get some insight on the data you're working with, as it can help you uncover relations between different features and visualize distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-chester",
   "metadata": {},
   "source": [
    "### Plotting with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-manual",
   "metadata": {},
   "source": [
    "Pandas offer plotting functionality with the `.plot` functions, which wrap-around matplotlib.pyplot's `plot()`. \n",
    "\n",
    "More info about plotting with pandas can be found at: https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html\n",
    "\n",
    "Here are two simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.plot.scatter(x=\"age\", y=\"fare\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"age\"].hist(bins=20, alpha=0.5)\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-proxy",
   "metadata": {},
   "source": [
    "### Plotting with seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-circus",
   "metadata": {},
   "source": [
    "Seaborn is a data visualization library based on matplotlib, which works very nicely with pandas DataFrames, allowing you to very quickly generate complex, informative (and aesthetically pleasing) plots. In this section, we'll show some of the plots that can be generated with seaborn.\n",
    "\n",
    "For a more in-depth seaborn tutorial, check out the official tutorial: https://seaborn.pydata.org/tutorial.html\n",
    "\n",
    "Let's improve on the two previous plots by adding the \"sex\" column as hue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=titanic, x=\"age\", y=\"fare\", hue=\"sex\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-outline",
   "metadata": {},
   "source": [
    "#### Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-wrist",
   "metadata": {},
   "source": [
    "Visualizing distributions is a good way to find heavy tails and other key information about a feature's distribution, which can help you decide whether or not to truncate / scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution with a histogram\n",
    "# KDE = Kernel Density Estimation\n",
    "sns.histplot(data=titanic, x=\"age\", hue=\"sex\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-strand",
   "metadata": {},
   "source": [
    "Empirical Cumulative Distribution Function (ECDF) plots are another great way to visualize distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(data=titanic, x=\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-dialogue",
   "metadata": {},
   "source": [
    "#### Categorical data\n",
    "\n",
    "Now, let's use a variety of plots offered by seaborn (such as count plots, box plots and violin plots) to gain a better insight on some of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic, x=\"pclass\", hue=\"who\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=titanic, x=\"pclass\", y=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=titanic, x=\"pclass\", y=\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-guard",
   "metadata": {},
   "source": [
    "Seaborn also computes confidence intervals using [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=titanic, y=\"survived\", x=\"pclass\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-activity",
   "metadata": {},
   "source": [
    "The previous plot reveals two key features for predicting which passengers survived the shipwreck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-surfing",
   "metadata": {},
   "source": [
    "#### Multi-plot grids\n",
    "\n",
    "More advanced (and harder to plot), but can offer very insightful visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.PairGrid(data=titanic, y_vars=\"survived\", x_vars=[\"pclass\", \"who\", \"alone\"])\n",
    "grid.map(sns.pointplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-franklin",
   "metadata": {},
   "source": [
    "That's all for seaborn!  For more examples of plots that can be generated with this library, check out the [seaborn example gallery](https://seaborn.pydata.org/examples/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-mystery",
   "metadata": {},
   "source": [
    "## 5. Data cleaning / wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-happening",
   "metadata": {},
   "source": [
    "Let's now cover how to use pandas to clean / transform our data into a proper dataset for machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick preview of the dataset (with columns removed from part 3)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-script",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-framing",
   "metadata": {},
   "source": [
    "Binning features is very easy with `cut` and `qcut`.\n",
    "\n",
    "- `pd.cut` bins values into discrete intervals. These bins are equal-width bins (uniform binning) when providing an `int` for  the `bins` parameters, but these bins can be whichever values you want by providing a sequence of scalars instead.\n",
    "- `pd.qcut` bins values using quantiles (quantile binning) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"age_group\"] = pd.cut(x=titanic[\"age\"], bins=5)\n",
    "titanic[\"age_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"fare_group\"] = pd.qcut(x=titanic[\"fare\"], q=5)\n",
    "titanic[\"fare_group\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-chosen",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a copy of the dataframe called `titanic_ml` to prevent destructive changes\n",
    "titanic_ml = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which columns have missing values\n",
    "titanic_ml.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach: check non-null count, which also informs us of how many values are NaN\n",
    "titanic_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-physics",
   "metadata": {},
   "source": [
    "#### Imputation\n",
    "Imputation can be done using `fillna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean imputation for age (just as an example, there are many other approaches that are valid)\n",
    "titanic_ml[\"age\"] = titanic_ml[\"age\"].fillna(titanic[\"age\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-clock",
   "metadata": {},
   "source": [
    "#### Deletion\n",
    "\n",
    "`dropna()` can be used for deletion.\n",
    "- The `subset` parameter can be used to only drop missing values from a few columns / columns.\n",
    "- `axis=0` drops rows, `axis=1` drops columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 2 rows don't have NaN for embark_town, let's drop it\n",
    "titanic_ml = titanic_ml.dropna(subset=[\"embark_town\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the columns containing NaN\n",
    "titanic_ml = titanic_ml.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does our data look like now?\n",
    "titanic_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-sentence",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-region",
   "metadata": {},
   "source": [
    "For most ML algorithms, we want our data to be entirely numerical, this requires encoding categorical features.\n",
    "\n",
    "One-hot encoding can be performed using `pd.get_dummies()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_ml = pd.get_dummies(titanic_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-interpretation",
   "metadata": {},
   "source": [
    "### To NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-terror",
   "metadata": {},
   "source": [
    "All our columns are now numeric, we can further convert them all to the same data type (if needed) using `astype()` and then to NumPy using `to_numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_ml.drop(columns=\"survived\").astype(float).to_numpy()\n",
    "y = titanic_ml[\"survived\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-senate",
   "metadata": {},
   "source": [
    "And there we go! We covered the basics of pandas, as well as all the steps needed to go from a raw dataset to one usable by ML algorithms.\n",
    "\n",
    "This processed dataset can now be used for classification with whichever package you desire (e.g. NumPy, as was done in previous weeks, or PyTorch and scikit-learn as we'll see later on).\n",
    "\n",
    "Pandas is a very flexible package with many use cases, feel free to check out the additional resources to learn more about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-aruba",
   "metadata": {},
   "source": [
    "## Additional pandas resources\n",
    "\n",
    "- Pandas Cheatsheet: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf **<- VERY USEFUL**\n",
    "- Pandas User Guide: https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html\n",
    "- API Reference: https://pandas.pydata.org/pandas-docs/stable/reference/index.html#api\n",
    "- Chapter 3 of the Python Data Science Handbook: https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html\n",
    "- Kaggle Pandas course: https://www.kaggle.com/learn/pandas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
